{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"DLL_COVID_TRAIN.csv\", parse_dates=[\"dateRep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>dateRep</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>popData2018</th>\n",
       "      <th>GDP (current US$)</th>\n",
       "      <th>GDP per capita (current US$)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Current health expenditure per capita (current US$)</th>\n",
       "      <th>Current health expenditure (% of GDP)</th>\n",
       "      <th>Hospital beds (per 1,000 people)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>1.936297e+10</td>\n",
       "      <td>520.896603</td>\n",
       "      <td>97.7</td>\n",
       "      <td>67.12265</td>\n",
       "      <td>11.777194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>1.936297e+10</td>\n",
       "      <td>520.896603</td>\n",
       "      <td>97.7</td>\n",
       "      <td>67.12265</td>\n",
       "      <td>11.777194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>1.936297e+10</td>\n",
       "      <td>520.896603</td>\n",
       "      <td>97.7</td>\n",
       "      <td>67.12265</td>\n",
       "      <td>11.777194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>1.936297e+10</td>\n",
       "      <td>520.896603</td>\n",
       "      <td>97.7</td>\n",
       "      <td>67.12265</td>\n",
       "      <td>11.777194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>1.936297e+10</td>\n",
       "      <td>520.896603</td>\n",
       "      <td>97.7</td>\n",
       "      <td>67.12265</td>\n",
       "      <td>11.777194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  countryterritoryCode    dateRep  cases  deaths countriesAndTerritories  \\\n",
       "0                  AFG 2020-04-17     10       4             Afghanistan   \n",
       "1                  AFG 2020-04-16     70       2             Afghanistan   \n",
       "2                  AFG 2020-04-15     49       2             Afghanistan   \n",
       "3                  AFG 2020-04-14     58       3             Afghanistan   \n",
       "4                  AFG 2020-04-13     52       0             Afghanistan   \n",
       "\n",
       "   popData2018  GDP (current US$)  GDP per capita (current US$)  \\\n",
       "0   37172386.0       1.936297e+10                    520.896603   \n",
       "1   37172386.0       1.936297e+10                    520.896603   \n",
       "2   37172386.0       1.936297e+10                    520.896603   \n",
       "3   37172386.0       1.936297e+10                    520.896603   \n",
       "4   37172386.0       1.936297e+10                    520.896603   \n",
       "\n",
       "   Access to electricity (% of population)  \\\n",
       "0                                     97.7   \n",
       "1                                     97.7   \n",
       "2                                     97.7   \n",
       "3                                     97.7   \n",
       "4                                     97.7   \n",
       "\n",
       "   Current health expenditure per capita (current US$)  \\\n",
       "0                                           67.12265     \n",
       "1                                           67.12265     \n",
       "2                                           67.12265     \n",
       "3                                           67.12265     \n",
       "4                                           67.12265     \n",
       "\n",
       "   Current health expenditure (% of GDP)  Hospital beds (per 1,000 people)  \n",
       "0                              11.777194                               0.5  \n",
       "1                              11.777194                               0.5  \n",
       "2                              11.777194                               0.5  \n",
       "3                              11.777194                               0.5  \n",
       "4                              11.777194                               0.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sort_values(\"dateRep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcast_days = 7\n",
    "split_date = dataset[\"dateRep\"].max() - np.timedelta64(forcast_days, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset.loc[dataset[\"dateRep\"] < split_date]\n",
    "test_df = dataset.loc[dataset[\"dateRep\"] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>popData2018</th>\n",
       "      <th>GDP (current US$)</th>\n",
       "      <th>GDP per capita (current US$)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Current health expenditure per capita (current US$)</th>\n",
       "      <th>Current health expenditure (% of GDP)</th>\n",
       "      <th>Hospital beds (per 1,000 people)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9626.000000</td>\n",
       "      <td>9626.000000</td>\n",
       "      <td>9.607000e+03</td>\n",
       "      <td>9.390000e+03</td>\n",
       "      <td>9390.000000</td>\n",
       "      <td>9440.000000</td>\n",
       "      <td>8966.000000</td>\n",
       "      <td>8966.000000</td>\n",
       "      <td>9185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>153.346354</td>\n",
       "      <td>9.122065</td>\n",
       "      <td>6.361825e+07</td>\n",
       "      <td>8.430790e+11</td>\n",
       "      <td>25128.295292</td>\n",
       "      <td>92.970108</td>\n",
       "      <td>1788.721743</td>\n",
       "      <td>6.865349</td>\n",
       "      <td>3.473547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1190.172484</td>\n",
       "      <td>75.314339</td>\n",
       "      <td>2.001526e+08</td>\n",
       "      <td>2.608225e+12</td>\n",
       "      <td>30322.567348</td>\n",
       "      <td>17.922541</td>\n",
       "      <td>2287.713332</td>\n",
       "      <td>2.773843</td>\n",
       "      <td>2.852989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>4.222968e+08</td>\n",
       "      <td>271.752044</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>19.431646</td>\n",
       "      <td>1.181210</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.731000e+06</td>\n",
       "      <td>2.454247e+10</td>\n",
       "      <td>4114.715061</td>\n",
       "      <td>99.506447</td>\n",
       "      <td>204.492249</td>\n",
       "      <td>4.748105</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.062570e+07</td>\n",
       "      <td>1.406454e+11</td>\n",
       "      <td>11373.233003</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>587.646301</td>\n",
       "      <td>6.541954</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.222843e+07</td>\n",
       "      <td>4.549676e+11</td>\n",
       "      <td>41715.029284</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2840.130615</td>\n",
       "      <td>8.873130</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34272.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>1.392730e+09</td>\n",
       "      <td>2.054434e+13</td>\n",
       "      <td>185741.279992</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10246.138672</td>\n",
       "      <td>17.061269</td>\n",
       "      <td>18.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cases       deaths   popData2018  GDP (current US$)  \\\n",
       "count   9626.000000  9626.000000  9.607000e+03       9.390000e+03   \n",
       "mean     153.346354     9.122065  6.361825e+07       8.430790e+11   \n",
       "std     1190.172484    75.314339  2.001526e+08       2.608225e+12   \n",
       "min        0.000000     0.000000  1.000000e+03       4.222968e+08   \n",
       "25%        0.000000     0.000000  3.731000e+06       2.454247e+10   \n",
       "50%        0.000000     0.000000  1.062570e+07       1.406454e+11   \n",
       "75%       14.000000     0.000000  4.222843e+07       4.549676e+11   \n",
       "max    34272.000000  2004.000000  1.392730e+09       2.054434e+13   \n",
       "\n",
       "       GDP per capita (current US$)  Access to electricity (% of population)  \\\n",
       "count                   9390.000000                              9440.000000   \n",
       "mean                   25128.295292                                92.970108   \n",
       "std                    30322.567348                                17.922541   \n",
       "min                      271.752044                                 9.300000   \n",
       "25%                     4114.715061                                99.506447   \n",
       "50%                    11373.233003                               100.000000   \n",
       "75%                    41715.029284                               100.000000   \n",
       "max                   185741.279992                               100.000000   \n",
       "\n",
       "       Current health expenditure per capita (current US$)  \\\n",
       "count                                        8966.000000     \n",
       "mean                                         1788.721743     \n",
       "std                                          2287.713332     \n",
       "min                                            19.431646     \n",
       "25%                                           204.492249     \n",
       "50%                                           587.646301     \n",
       "75%                                          2840.130615     \n",
       "max                                         10246.138672     \n",
       "\n",
       "       Current health expenditure (% of GDP)  Hospital beds (per 1,000 people)  \n",
       "count                            8966.000000                       9185.000000  \n",
       "mean                                6.865349                          3.473547  \n",
       "std                                 2.773843                          2.852989  \n",
       "min                                 1.181210                          0.100000  \n",
       "25%                                 4.748105                          1.500000  \n",
       "50%                                 6.541954                          2.800000  \n",
       "75%                                 8.873130                          4.600000  \n",
       "max                                17.061269                         18.680000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countryterritoryCode                                     0\n",
       "dateRep                                                  0\n",
       "cases                                                    0\n",
       "deaths                                                   0\n",
       "countriesAndTerritories                                  0\n",
       "popData2018                                             19\n",
       "GDP (current US$)                                      236\n",
       "GDP per capita (current US$)                           236\n",
       "Access to electricity (% of population)                186\n",
       "Current health expenditure per capita (current US$)    660\n",
       "Current health expenditure (% of GDP)                  660\n",
       "Hospital beds (per 1,000 people)                       441\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nans with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting LSTM model to the one country time series series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Italy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = train_df[\n",
    "    train_df[\"countriesAndTerritories\"] == country\n",
    "]  # [\"cases\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_country = test_df[test_df[\"countriesAndTerritories\"] == country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (\n",
    "    len(train_df.columns) - 3\n",
    ")  # we don't use countryterritoryCode, dateRep, and countriesAndTerritories\n",
    "hidden_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class train_dataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, length: int = 7):\n",
    "        self.df = df.copy().drop(\n",
    "            columns=[\"countryterritoryCode\", \"countriesAndTerritories\"]\n",
    "        )\n",
    "        self.label_columns = [\"cases\", \"deaths\"]\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx: idx + self.length]\n",
    "\n",
    "        cases = torch.tensor(sample.pop(\"cases\").to_numpy()).float()\n",
    "        cases = cases.unsqueeze(1)\n",
    "        deaths = torch.tensor(sample.pop(\"deaths\").to_numpy()).float()\n",
    "        deaths = deaths.unsqueeze(1)\n",
    "\n",
    "        date = sample.pop(\"dateRep\")\n",
    "        sample = torch.tensor(sample.to_numpy()).float()#[None, :]\n",
    "        return sample, cases, deaths\n",
    "\n",
    "\n",
    "class MSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        return self.mse(torch.log(pred + 1e-8), torch.log(actual + 1e-8))\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_lstm_layers: int):\n",
    "        super().__init__()\n",
    "        self.fc1 =  nn.Linear(input_size, 32)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32, hidden_size=hidden_size, num_layers=num_lstm_layers\n",
    "        )\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x, _ = self.lstm(x)\n",
    "        y = F.relu(self.fc2(x))\n",
    "        return y\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    dataset: Dataset, model: nn.Module, epochs: int = 6, batch_size=32\n",
    ") -> nn.Module:\n",
    "    crierion = MSLELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x, cases, deaths in dataloader:\n",
    "            model.zero_grad()\n",
    "            cases_pred = model(x)\n",
    "            loss = crierion(cases_pred[-1], cases[-1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(loss)\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        print(cases_pred.detach().numpy(), cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries[\"last_cases\"] = timeseries[\"cases\"].shift(1)\n",
    "timeseries[\"last_cases\"] = timeseries[\"last_cases\"].fillna(0)\n",
    "timeseries[\"last_deaths\"] = timeseries[\"deaths\"].shift(1)\n",
    "timeseries[\"last_deaths\"] = timeseries[\"last_deaths\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(245.9985, grad_fn=<MseLossBackward>)\n",
      "tensor(281.3477, grad_fn=<MseLossBackward>)\n",
      "tensor(107.9191, grad_fn=<MseLossBackward>)\n",
      "tensor(108.1400, grad_fn=<MseLossBackward>)\n",
      "tensor(80.7840, grad_fn=<MseLossBackward>)\n",
      "tensor(275.6723, grad_fn=<MseLossBackward>)\n",
      "tensor(236.8925, grad_fn=<MseLossBackward>)\n",
      "tensor(273.0522, grad_fn=<MseLossBackward>)\n",
      "tensor(269.9863, grad_fn=<MseLossBackward>)\n",
      "tensor(165.9465, grad_fn=<MseLossBackward>)\n",
      "tensor(95.1197, grad_fn=<MseLossBackward>)\n",
      "tensor(84.9289, grad_fn=<MseLossBackward>)\n",
      "tensor(50.4604, grad_fn=<MseLossBackward>)\n",
      "tensor(255.6067, grad_fn=<MseLossBackward>)\n",
      "tensor(252.9649, grad_fn=<MseLossBackward>)\n",
      "tensor(214.5064, grad_fn=<MseLossBackward>)\n",
      "tensor(239.9033, grad_fn=<MseLossBackward>)\n",
      "tensor(226.2612, grad_fn=<MseLossBackward>)\n",
      "tensor(170.1409, grad_fn=<MseLossBackward>)\n",
      "tensor(197.7975, grad_fn=<MseLossBackward>)\n",
      "tensor(168.9862, grad_fn=<MseLossBackward>)\n",
      "tensor(729.1535, grad_fn=<MseLossBackward>)\n",
      "tensor(637.3875, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(720.9083, grad_fn=<MseLossBackward>)\n",
      "tensor(729.3845, grad_fn=<MseLossBackward>)\n",
      "tensor(731.8824, grad_fn=<MseLossBackward>)\n",
      "tensor(731.8824, grad_fn=<MseLossBackward>)\n",
      "tensor(727.4003, grad_fn=<MseLossBackward>)\n",
      "tensor(606.9025, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(731.9175, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(432.5318, grad_fn=<MseLossBackward>)\n",
      "tensor(541.5970, grad_fn=<MseLossBackward>)\n",
      "tensor(207.6103, grad_fn=<MseLossBackward>)\n",
      "tensor(720.9083, grad_fn=<MseLossBackward>)\n",
      "tensor(577.0329, grad_fn=<MseLossBackward>)\n",
      "tensor(283.1515, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(714.6786, grad_fn=<MseLossBackward>)\n",
      "tensor(358.4162, grad_fn=<MseLossBackward>)\n",
      "tensor(719.5580, grad_fn=<MseLossBackward>)\n",
      "tensor(698.3807, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(718.5524, grad_fn=<MseLossBackward>)\n",
      "tensor(532.6157, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(688.8661, grad_fn=<MseLossBackward>)\n",
      "tensor(54.4290, grad_fn=<MseLossBackward>)\n",
      "tensor(54.4290, grad_fn=<MseLossBackward>)\n",
      "tensor(283.1515, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(637.3875, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(722.5886, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(54.4290, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(730.7952, grad_fn=<MseLossBackward>)\n",
      "tensor(729.3845, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(714.6786, grad_fn=<MseLossBackward>)\n",
      "tensor(54.4290, grad_fn=<MseLossBackward>)\n",
      "tensor(432.5318, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(566.0930, grad_fn=<MseLossBackward>)\n",
      "tensor(0., grad_fn=<MseLossBackward>)\n",
      "tensor(722.5886, grad_fn=<MseLossBackward>)\n",
      "tensor(678.1044, grad_fn=<MseLossBackward>)\n",
      "tensor(729.3845, grad_fn=<MseLossBackward>)\n",
      "tensor(207.6103, grad_fn=<MseLossBackward>)\n",
      "tensor(708.2111, grad_fn=<MseLossBackward>)\n",
      "tensor(714.7275, grad_fn=<MseLossBackward>)\n",
      "tensor(598.6163, grad_fn=<MseLossBackward>)\n",
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] tensor([[[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[5.3000e+01],\n",
      "         [9.7000e+01],\n",
      "         [9.3000e+01],\n",
      "         [7.8000e+01],\n",
      "         [2.5000e+02],\n",
      "         [2.3800e+02],\n",
      "         [2.4000e+02]],\n",
      "\n",
      "        [[5.3220e+03],\n",
      "         [5.9860e+03],\n",
      "         [6.5570e+03],\n",
      "         [5.5600e+03],\n",
      "         [4.7890e+03],\n",
      "         [5.2490e+03],\n",
      "         [5.2100e+03]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[4.2070e+03],\n",
      "         [5.3220e+03],\n",
      "         [5.9860e+03],\n",
      "         [6.5570e+03],\n",
      "         [5.5600e+03],\n",
      "         [4.7890e+03],\n",
      "         [5.2490e+03]],\n",
      "\n",
      "        [[2.4000e+02],\n",
      "         [5.6100e+02],\n",
      "         [3.4700e+02],\n",
      "         [4.6600e+02],\n",
      "         [5.8700e+02],\n",
      "         [7.6900e+02],\n",
      "         [7.7800e+02]],\n",
      "\n",
      "        [[7.7800e+02],\n",
      "         [1.2470e+03],\n",
      "         [1.4920e+03],\n",
      "         [1.7970e+03],\n",
      "         [9.7700e+02],\n",
      "         [2.3130e+03],\n",
      "         [2.6510e+03]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [3.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[2.3130e+03],\n",
      "         [2.6510e+03],\n",
      "         [2.5470e+03],\n",
      "         [3.4970e+03],\n",
      "         [2.8230e+03],\n",
      "         [4.0000e+03],\n",
      "         [3.5260e+03]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [1.4000e+01],\n",
      "         [6.2000e+01],\n",
      "         [5.3000e+01],\n",
      "         [9.7000e+01],\n",
      "         [9.3000e+01]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[5.8700e+02],\n",
      "         [7.6900e+02],\n",
      "         [7.7800e+02],\n",
      "         [1.2470e+03],\n",
      "         [1.4920e+03],\n",
      "         [1.7970e+03],\n",
      "         [9.7700e+02]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[9.7700e+02],\n",
      "         [2.3130e+03],\n",
      "         [2.6510e+03],\n",
      "         [2.5470e+03],\n",
      "         [3.4970e+03],\n",
      "         [2.8230e+03],\n",
      "         [4.0000e+03]],\n",
      "\n",
      "        [[6.2000e+01],\n",
      "         [5.3000e+01],\n",
      "         [9.7000e+01],\n",
      "         [9.3000e+01],\n",
      "         [7.8000e+01],\n",
      "         [2.5000e+02],\n",
      "         [2.3800e+02]],\n",
      "\n",
      "        [[5.2490e+03],\n",
      "         [5.2100e+03],\n",
      "         [6.1530e+03],\n",
      "         [5.9590e+03],\n",
      "         [5.9740e+03],\n",
      "         [5.2170e+03],\n",
      "         [4.0500e+03]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[3.4700e+02],\n",
      "         [4.6600e+02],\n",
      "         [5.8700e+02],\n",
      "         [7.6900e+02],\n",
      "         [7.7800e+02],\n",
      "         [1.2470e+03],\n",
      "         [1.4920e+03]],\n",
      "\n",
      "        [[3.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [3.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[5.2170e+03],\n",
      "         [4.0500e+03],\n",
      "         [4.0530e+03],\n",
      "         [4.7820e+03],\n",
      "         [4.6680e+03],\n",
      "         [4.5850e+03],\n",
      "         [4.8050e+03]],\n",
      "\n",
      "        [[0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00],\n",
      "         [0.0000e+00]],\n",
      "\n",
      "        [[4.6600e+02],\n",
      "         [5.8700e+02],\n",
      "         [7.6900e+02],\n",
      "         [7.7800e+02],\n",
      "         [1.2470e+03],\n",
      "         [1.4920e+03],\n",
      "         [1.7970e+03]],\n",
      "\n",
      "        [[2.3800e+02],\n",
      "         [2.4000e+02],\n",
      "         [5.6100e+02],\n",
      "         [3.4700e+02],\n",
      "         [4.6600e+02],\n",
      "         [5.8700e+02],\n",
      "         [7.6900e+02]]])\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_lstm_layers=num_layers)\n",
    "train_ds = train_dataset(timeseries)\n",
    "train_model(train_ds, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00]], dtype=torch.float64),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0]),\n",
       "  5470   2019-12-31\n",
       "  5469   2020-01-01\n",
       "  5468   2020-01-02\n",
       "  5467   2020-01-03\n",
       "  5466   2020-01-04\n",
       "  5465   2020-01-05\n",
       "  5464   2020-01-06\n",
       "  Name: dateRep, dtype: datetime64[ns]),\n",
       " (tensor([[6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00],\n",
       "          [6.0431e+07, 2.0839e+12, 3.4483e+04, 1.0000e+02, 2.8401e+03, 8.8403e+00,\n",
       "           3.4000e+00]], dtype=torch.float64),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0]),\n",
       "  5469   2020-01-01\n",
       "  5468   2020-01-02\n",
       "  5467   2020-01-03\n",
       "  5466   2020-01-04\n",
       "  5465   2020-01-05\n",
       "  5464   2020-01-06\n",
       "  5463   2020-01-07\n",
       "  Name: dateRep, dtype: datetime64[ns]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0], train_ds[1], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSLE_loss(one, two):\n",
    "    loss = np.mean((np.log1p(one) - np.log1p(two)) ** 2)  # MSLE loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def run_arima(train, test, order):\n",
    "    model = ARIMA(train, order=order)\n",
    "    model = model.fit(disp=0)\n",
    "    predictions = model.forecast(steps=len(test))[0]\n",
    "    loss = MSLE_loss(test, predictions)  # MSLE loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def evaluate_arima_params(train, test, p_list, d_list, q_list, verbose=0):\n",
    "    best_loss, best_params = float(\"inf\"), (0, 0, 0)\n",
    "    for params in itertools.product(p_list, d_list, q_list):\n",
    "        try:\n",
    "            loss = run_arima(train, test, params)\n",
    "            if loss < best_loss:\n",
    "                best_loss, best_params = loss, params\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"Best ARIMA params {best_params} with loss={best_loss}\")\n",
    "    return best_loss, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028478075717193796"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_arima(timeseries, test_one_country[\"cases\"], (1, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA params (1, 0, 2) with loss=0.02806542308488452\n"
     ]
    }
   ],
   "source": [
    "loss, params = evaluate_arima_params(\n",
    "    timeseries, test_one_country[\"cases\"], [0, 1, 2], [0, 1, 2], [0, 1, 2], verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(timeseries, order=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.forecast(steps=len(test_one_country))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd6c42c99d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preds, label=\"Predictions\")\n",
    "plt.plot(test_one_country[\"cases\"].tolist(), label=\"Ground truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this on all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = dataset[\"countriesAndTerritories\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "loss, params = evaluate_arima_params(\n",
    "    timeseries, test_one_country[\"cases\"], [0, 1, 2], [0, 1, 2], [0, 1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell will take few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions = pd.DataFrame()\n",
    "for country in country_list:\n",
    "    timeseries = train[train[\"countriesAndTerritories\"] == country][\"cases\"].tolist()\n",
    "    test_one_country = test[test[\"countriesAndTerritories\"] == country]\n",
    "    if len(test_one_country) == 0:\n",
    "        print(f\"There is no test data for {country}\")\n",
    "        continue\n",
    "    loss, params = evaluate_arima_params(\n",
    "        timeseries, test_one_country[\"cases\"], [0, 1, 2], [0, 1, 2], [0, 1, 2]\n",
    "    )\n",
    "    if len(timeseries) == 0:\n",
    "        preds = 0 * len(test_one_country)\n",
    "    elif len(timeseries) < len(test_one_country):\n",
    "        preds = timeseries[-1] * len(test_one_country)\n",
    "    else:\n",
    "        model = ARIMA(timeseries, order=params)\n",
    "        model = model.fit(disp=False)\n",
    "        preds = model.forecast(steps=len(test_one_country))[0]\n",
    "    test_one_country[\"predictions\"] = preds\n",
    "    predictions = predictions.append(test_one_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6059281011533988"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSLE_loss(predictions[\"cases\"], predictions[\"predictions\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
